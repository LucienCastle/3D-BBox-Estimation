{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90da08f-c339-4e81-a4be-7f5eb4d5c88b",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62cd5fd-3cf8-4dc1-9855-7619b2836fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from model import bbox_3D_net\n",
    "from preprocess_data import get_cam_data, get_dect2D_data\n",
    "from post_processing import gen_3D_box,draw_3D_box,draw_2D_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f258d6-b666-4511-baeb-35d771ccd13d",
   "metadata": {},
   "source": [
    "### Load 3D box estimator with saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33318bbc-22fa-4019-a764-e2811e9cebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sumit\\anaconda3\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "model = bbox_3D_net((224,224,3))\n",
    "\n",
    "model.load_weights('weights_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8540299-c748-4c78-a373-0791d4d4f639",
   "metadata": {},
   "source": [
    "### Path of validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713ddf19-4b52-4a2d-8080-bb33534b8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'test/image_2/'\n",
    "box2d_dir = 'test/label_2/'\n",
    "calib_dir = 'test/calib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363bee56-6354-4a03-acc4-0d5f44c1f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each class get average dimensions as per VOC data\n",
    "classes = ['Car','Van','Truck','Pedestrian','Person_sitting','Cyclist','Tram']\n",
    "cls_to_ind = {cls:i for i,cls in enumerate(classes)}\n",
    "\n",
    "dims_avg = np.loadtxt(r'voc_dims.txt',delimiter=',')\n",
    "\n",
    "# get validation images\n",
    "all_image = sorted(os.listdir(image_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd5c7-81b2-4163-8894-38fc42256324",
   "metadata": {},
   "source": [
    "### Estimating 3D bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b03196-8a82-4b86-b54d-99d0630369fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the images\n",
    "for f in all_image:\n",
    "    # load label and camera calibration files for corresponding image\n",
    "    image_file = image_dir + f\n",
    "    box2d_file = box2d_dir + f.replace('png', 'txt')\n",
    "    calib_file = calib_dir + f.replace('png', 'txt')\n",
    "    cam_to_img = get_cam_data(calib_file)\n",
    "    fx = cam_to_img[0][0]\n",
    "    u0 = cam_to_img[0][2]\n",
    "    v0 = cam_to_img[1][2]\n",
    "    \n",
    "    # directory to store labels of predicted boxes for evaluation purposes\n",
    "    box3d_file = 'output_label/'+ f.replace('png','txt')\n",
    "    \n",
    "    with open(box3d_file, 'w') as box3d:\n",
    "        img = cv2.imread(image_file)\n",
    "        \n",
    "        # iterate over objects\n",
    "        for line in open(box2d_file):\n",
    "            line = line.strip().split(' ')\n",
    "            cls = line[0]\n",
    "            \n",
    "            if cls not in classes:\n",
    "                # if class of current object is not in our list of class skip it\n",
    "                box3d.write(' '.join([str(item) for item in line])+'\\n')\n",
    "            \n",
    "            if cls in classes:\n",
    "                # get the truncated and occluded state of object\n",
    "                truncated = np.abs(float(line[1]))\n",
    "                occluded  = np.abs(float(line[2]))\n",
    "\n",
    "                # get 2D box coordinates\n",
    "                obj = {'xmin':int(float(line[4])),\n",
    "                       'ymin':int(float(line[5])),\n",
    "                       'xmax':int(float(line[6])),\n",
    "                       'ymax':int(float(line[7])),\n",
    "                      }\n",
    "                \n",
    "                box_2D = np.array([float(number) for number in line[4:8]])\n",
    "                \n",
    "                # performing predictions on easy split(with less truncation and occlusion)\n",
    "                if truncated < 0.3 and occluded <= 1: \n",
    "                    # generate patch to estimate bounding box\n",
    "                    patch = img[obj['ymin']:obj['ymax'],obj['xmin']:obj['xmax']]\n",
    "                    patch = cv2.resize(patch, (224, 224))\n",
    "                    patch = patch - np.array([[[103.939, 116.779, 123.68]]])\n",
    "                    patch = np.expand_dims(patch, 0)\n",
    "                    \n",
    "                    # predict dimension and orientation of object in the patch\n",
    "                    prediction = model.predict(patch)\n",
    "\n",
    "                    # compute dims\n",
    "                    dims = dims_avg[cls_to_ind[cls]] + prediction[0][0]\n",
    "                    \n",
    "                    # for bin with maximum confidence get the theta localized\n",
    "                    max_anc = np.argmax(prediction[2][0])\n",
    "                    anchors = prediction[1][0][max_anc]\n",
    "                    if anchors[1] > 0:\n",
    "                        angle_offset = np.arccos(anchors[0])\n",
    "                    else:\n",
    "                        angle_offset = -np.arccos(anchors[0])\n",
    "                    \n",
    "                    # calculate theta loc in image coordinates\n",
    "                    bin_num = prediction[2][0].shape[0]\n",
    "                    wedge = 2. * np.pi / bin_num\n",
    "                    theta_loc = angle_offset + max_anc * wedge\n",
    "\n",
    "                    if theta_loc > 2*np.pi: \n",
    "                        theta_l = theta_loc % (2*np.pi)\n",
    "                    else:\n",
    "                        theta_l = theta_loc\n",
    "                    theta_loc = theta_l - np.pi / 2\n",
    "\n",
    "                    if theta_loc > np.pi:\n",
    "                        theta_loc -= 2 * np.pi\n",
    "                    theta_loc = round(theta_loc, 2)\n",
    "\n",
    "                    # get the observers angle\n",
    "                    box2d_center_x = (obj['xmin'] + obj['xmax']) / 2.0\n",
    "                    u_dist = box2d_center_x - u0\n",
    "                    \n",
    "                    # Transfer arctan() from (-pi/2,pi/2) to (0,pi)\n",
    "                    theta_ray = np.arctan(fx / u_dist)\n",
    "                    \n",
    "                    if theta_ray<0:\n",
    "                        theta_ray = theta_ray+np.pi\n",
    "\n",
    "                    rot_global = theta_loc + theta_ray\n",
    "                    rot_global = round(rot_global, 2)\n",
    "                    \n",
    "                    # calculate yaw of object\n",
    "                    yaw = - rot_global\n",
    "                    \n",
    "                    # store alpha in results\n",
    "                    line[3] = str(theta_loc)\n",
    "                    \n",
    "                    yrot = yaw - np.pi/2\n",
    "                    if yrot < -np.pi:\n",
    "                        yrot = yrot + 2.*np.pi\n",
    "                    \n",
    "                    # store rotation-y\n",
    "                    line[-1] = str(yrot)\n",
    "\n",
    "                    line = line[:8] + list(dims) + line[11:]\n",
    "\n",
    "                    line = ' '.join([str(item) for item in line]) + '\\n'\n",
    "                    box3d.write(line)\n",
    "                    \n",
    "                    # generate and draw 3D box\n",
    "                    points2D, error = gen_3D_box(yaw, dims, cam_to_img, box_2D)\n",
    "                    draw_3D_box(img, points2D)\n",
    "                else:\n",
    "                    # if object is too much truncated or occluded draw 2D box\n",
    "                    box3d.write(' '.join([str(item) for item in line])+'\\n')\n",
    "                    draw_2D_box(img,box_2D)\n",
    "    \n",
    "    # uncomment following 3 lines to see each of the estimated box drawn on image or use next cell\n",
    "    # cv2.imshow(f, img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    cv2.imwrite('output/'+ f.replace('png','jpg'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc8ea68d-05f7-46c6-8057-b77fd02986fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'output/'\n",
    "all_results = sorted(os.listdir(result_dir))\n",
    "\n",
    "# number results to check\n",
    "num_show = 5\n",
    "for i in range(num_show):\n",
    "    idx = np.random.choice(all_results)\n",
    "    img = cv2.imread(result_dir+idx)\n",
    "    cv2.imshow('Result',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f403c-4711-434a-9047-c672e254c315",
   "metadata": {},
   "source": [
    "# Evaluation Code\n",
    "--label_path = gt_label_directory<br/>\n",
    "--result_path = predicted_labels_directory<br/>\n",
    "--label_split_file = file with list of images used for testing<br/>\n",
    "--current_class = class to evaluate<br/>\n",
    "--coco = if dataset in coco format<br/>\n",
    "<br/>\n",
    "## Usage:\n",
    "python evaluate.py evaluate --label_path=test/label_2/ --result_path=output_label/ --label_split_file=test/val.txt  --current_class=0 --coco=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfa1261c-4171-47f1-a585-b2725d81b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit\\anaconda3\\envs\\myenv2\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (10) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\Sumit\\anaconda3\\envs\\myenv2\\lib\\site-packages\\numba\\core\\typed_passes.py:329: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.readthedocs.io/en/stable/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"kitti-object-eval-python-master\\eval.py\", line 135:\n",
      "@numba.jit(nopython=True, parallel=True)\n",
      "def d3_box_overlap_kernel(boxes,\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaPerformanceWarning(msg,\n",
      "C:\\Users\\Sumit\\anaconda3\\envs\\myenv2\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (10) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car AP(Average Precision)@0.70, 0.70, 0.70:\n",
      "bbox AP:100.00, 100.00, 100.00\n",
      "bev  AP:44.28, 57.90, 46.38\n",
      "3d   AP:25.61, 36.20, 27.21\n",
      "aos  AP:87.93, 82.79, 87.01\n",
      "Car AP(Average Precision)@0.70, 0.50, 0.50:\n",
      "bbox AP:100.00, 100.00, 100.00\n",
      "bev  AP:50.99, 67.44, 49.10\n",
      "3d   AP:50.66, 60.81, 48.70\n",
      "aos  AP:87.93, 82.79, 87.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python kitti-object-eval-python-master/evaluate.py evaluate --label_path=test/label_2/ --result_path=output_label/ --label_split_file=test/val.txt  --current_class=0 --coco=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252adde-83a8-41fe-a44d-cffedcddc148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
